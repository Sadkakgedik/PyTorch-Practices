{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 2 : Building a Convolutional Neural Network (CNN)\n",
    "CNN's are also known as ConvNets.\n",
    "\n",
    "They are known for their ability to find patterns in visual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "0.15.0\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "# Import torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm\n",
    "\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=datasets.FashionMNIST(\n",
    "    root=\"data\", #where to download data to\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(), #How do we want to transform the data ?\n",
    "    target_transform=None  #How do we want to transform the labels/targets ?\n",
    ")\n",
    "\n",
    "test_data=datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")\n",
    "len(train_data),len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "image,label=train_data[0]\n",
    "class_names=train_data.classes\n",
    "class_to_idx = train_data.class_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x227f8913760>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x227f8913cd0>)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "#Turn datasets into iterables ( batches )\n",
    "train_dataloader=DataLoader(dataset=train_data,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=True)\n",
    "test_dataloader=DataLoader(dataset=test_data,\n",
    "                           batch_size=BATCH_SIZE,\n",
    "                           shuffle=False)\n",
    "\n",
    "train_dataloader,test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "class FashionMNISTModelV2(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architecture that replicates TinyVGG\n",
    "    model from CNN explainer site.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_shape: int,\n",
    "                 hidden_units: int,\n",
    "                 output_shape: int):\n",
    "        super().__init__()\n",
    "        self.conv_block_1=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1), #hyperparameters of Conv2d\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)#kernel size can also be a tuple such as (2,2)\n",
    "\n",
    "        )\n",
    "        self.conv_block_2=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.classifier_layer=nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*7*7,\n",
    "                      out_features=output_shape)#out features -> class_names\n",
    "        )\n",
    "\n",
    "    def forward(self,x:torch.tensor):\n",
    "        x=self.conv_block_1(x)\n",
    "        #print(f\"Output shape after conv block 1: {x.shape}\")\n",
    "        x=self.conv_block_2(x)\n",
    "        #print(f\"Output shape after conv block 2: {x.shape}\")\n",
    "        x=self.classifier_layer(x)\n",
    "        #print(f\"Output shape after classifier layer: {x.shape}\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model:torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn:torch.nn.Module,\n",
    "               accuracy_fn):\n",
    "    \"\"\" Returns a dictionary containing the results of model predicting on data_loader\"\"\"\n",
    "    loss,acc=0,0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X,y in tqdm(data_loader):\n",
    "            X,y=X.to(device),y.to(device)\n",
    "            #make preds\n",
    "            y_pred=model(X)\n",
    "\n",
    "            #Accumulate the loss and acc values per batch\n",
    "            loss += loss_fn(y_pred,y)\n",
    "            acc += accuracy_fn(y_true=y,\n",
    "                               y_pred=y_pred.argmax(dim=1))\n",
    "        # Scale loss and acc to find the avarage loss/ acc per batch\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "\n",
    "    return {\"model_name\": model.__class__.__name__,#only works when model was created with a class\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "def train_step(model:torch.nn.Module,\n",
    "               data_loader:torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device:torch.device=device):\n",
    "    \"\"\"Performs a training with model trying to learn on data_loader.\"\"\"\n",
    "    train_loss,train_acc=0,0\n",
    "    \n",
    "    #Put model into training mode\n",
    "    model.train()\n",
    "\n",
    "    # Add a loop to loop through training batches X-> image, y->label(target)\n",
    "    for batch , (X,y) in enumerate(data_loader):\n",
    "        \n",
    "        #Put data on target device\n",
    "        X,y=X.to(device),y.to(device)\n",
    "        \n",
    "        #1. Forward pass (outputs the raw logits from the model)\n",
    "        y_pred=model(X)\n",
    "\n",
    "        #2. Calculate the loss\n",
    "        loss=loss_fn(y_pred,y)\n",
    "        train_loss +=loss #accumulate train loss\n",
    "        train_acc+=accuracy_fn(y_true=y,\n",
    "                               y_pred=y_pred.argmax(dim=1)) #go from logits->prediction labels\n",
    "        \n",
    "        #3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        #5. Optimizer\n",
    "        optimizer.step() \n",
    "\n",
    "    train_loss/=len(data_loader)\n",
    "    train_acc/=len(data_loader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model:torch.nn.Module,\n",
    "              data_loader:torch.utils.data.DataLoader,\n",
    "              loss_fn:torch.nn.Module,\n",
    "              accuracy_fn,\n",
    "              device:torch.device=device):\n",
    "    \"\"\"Performs a testing loop step on model going over data_loader.\"\"\"\n",
    "    test_loss,test_acc=0,0\n",
    "\n",
    "    #Put model into eval mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X,y in data_loader:\n",
    "            #Data into device\n",
    "            X,y=X.to(device),y.to(device)\n",
    "            \n",
    "            #1. Forward pass\n",
    "            test_pred=model(X)\n",
    "\n",
    "            #2. Calculate loss and acc(accumulatively)\n",
    "            test_loss+=loss_fn(test_pred,y)\n",
    "            test_acc+=accuracy_fn(y_true=y,\n",
    "                                  y_pred=test_pred.argmax(dim=1))\n",
    "            \n",
    "        # Calculate the test loss/acc average per patch\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f\"\\nTest loss: {test_loss:.4f}, Test acc {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: torch.Size([1, 28, 28])\n",
      "Label: 2, label size: torch.Size([])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_features_batch,train_labels_batch=next(iter(train_dataloader))\n",
    "train_features_batch.shape,train_labels_batch.shape\n",
    "random_idx=torch.randint(0,len(train_features_batch),size=[1]).item()\n",
    "img,label=train_features_batch[random_idx],train_labels_batch[random_idx]\n",
    "plt.imshow(img.squeeze(),cmap=\"gray\")\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)\n",
    "print(f\"Image size: {img.shape}\")\n",
    "print(f\"Label: {label}, label size: {label.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "#input shape is 1 beacuse we have 1 color channel\n",
    "model_2=FashionMNISTModelV2(input_shape=1,\n",
    "                            hidden_units=30,\n",
    "                            output_shape=len(class_names)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stepping through nn.Conv2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: torch.Size([32, 3, 64, 64])\n",
      "Single images shape: torch.Size([3, 64, 64])\n",
      "Test image:\n",
      " tensor([[[ 1.9269,  1.4873,  0.9007,  ...,  1.8446, -1.1845,  1.3835],\n",
      "         [ 1.4451,  0.8564,  2.2181,  ...,  0.3399,  0.7200,  0.4114],\n",
      "         [ 1.9312,  1.0119, -1.4364,  ..., -0.5558,  0.7043,  0.7099],\n",
      "         ...,\n",
      "         [-0.5610, -0.4830,  0.4770,  ..., -0.2713, -0.9537, -0.6737],\n",
      "         [ 0.3076, -0.1277,  0.0366,  ..., -2.0060,  0.2824, -0.8111],\n",
      "         [-1.5486,  0.0485, -0.7712,  ..., -0.1403,  0.9416, -0.0118]],\n",
      "\n",
      "        [[-0.5197,  1.8524,  1.8365,  ...,  0.8935, -1.5114, -0.8515],\n",
      "         [ 2.0818,  1.0677, -1.4277,  ...,  1.6612, -2.6223, -0.4319],\n",
      "         [-0.1010, -0.4388, -1.9775,  ...,  0.2106,  0.2536, -0.7318],\n",
      "         ...,\n",
      "         [ 0.2779,  0.7342, -0.3736,  ..., -0.4601,  0.1815,  0.1850],\n",
      "         [ 0.7205, -0.2833,  0.0937,  ..., -0.1002, -2.3609,  2.2465],\n",
      "         [-1.3242, -0.1973,  0.2920,  ...,  0.5409,  0.6940,  1.8563]],\n",
      "\n",
      "        [[-0.7978,  1.0261,  1.1465,  ...,  1.2134,  0.9354, -0.0780],\n",
      "         [-1.4647, -1.9571,  0.1017,  ..., -1.9986, -0.7409,  0.7011],\n",
      "         [-1.3938,  0.8466, -1.7191,  ..., -1.1867,  0.1320,  0.3407],\n",
      "         ...,\n",
      "         [ 0.8206, -0.3745,  1.2499,  ..., -0.0676,  0.0385,  0.6335],\n",
      "         [-0.5589, -0.3393,  0.2347,  ...,  2.1181,  2.4569,  1.3083],\n",
      "         [-0.4092,  1.5199,  0.2401,  ..., -0.2558,  0.7870,  0.9924]]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "images=torch.randn(size=(32,3,64,64))\n",
    "test_image=images[0]\n",
    "\n",
    "print(f\"Image batch shape: {images.shape}\")\n",
    "print(f\"Single images shape: {test_image.shape}\")\n",
    "print(f\"Test image:\\n {test_image}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64, 64])"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "conv_layer=nn.Conv2d(in_channels=3,\n",
    "                     out_channels=64,\n",
    "                     kernel_size=3,\n",
    "                     stride=1,\n",
    "                     padding=1).to(device)\n",
    "\n",
    "conv_output=conv_layer(test_image.unsqueeze(0).to(device))\n",
    "conv_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image original shape: torch.Size([3, 64, 64])\n",
      "Test image with unsqueezed dimension: torch.Size([1, 3, 64, 64])\n",
      "Shape after conv layer: torch.Size([1, 64, 64, 64])\n",
      "Shape after max pool : torch.Size([1, 64, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "#Print out original image shape without unsqueezed dimension\n",
    "print(f\"Test image original shape: {test_image.shape}\")\n",
    "print(f\"Test image with unsqueezed dimension: {test_image.unsqueeze(0).shape}\")\n",
    "\n",
    "#Create a sample nn.MaxPool2d layer\n",
    "max_pool_layer=nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "#Pass data\n",
    "test_image_through_conv=conv_layer(test_image.unsqueeze(dim=0).to(device))\n",
    "print(f\"Shape after conv layer: {test_image_through_conv.shape}\")\n",
    "\n",
    "test_image_through_conv_and_max_pool=max_pool_layer(test_image_through_conv)\n",
    "print(f\"Shape after max pool : {test_image_through_conv_and_max_pool.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random tensor:\n",
      "tensor([[[[0.3367, 0.1288],\n",
      "          [0.2345, 0.2303]]]])\n",
      "Random tensor shape:torch.Size([1, 1, 2, 2])\n",
      "\n",
      "Max pool tensor:\n",
      "tensor([[[[0.3367]]]])\n",
      "Max pool tensor shape: torch.Size([1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "random_tensor=torch.randn(size=(1,1,2,2))\n",
    "print(f\"\\nRandom tensor:\\n{random_tensor}\")\n",
    "print(f\"Random tensor shape:{random_tensor.shape}\")\n",
    "\n",
    "max_pool_layer=nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "max_pool_tensor=max_pool_layer(random_tensor)\n",
    "\n",
    "print(f\"\\nMax pool tensor:\\n{max_pool_tensor}\")\n",
    "print(f\"Max pool tensor shape: {max_pool_tensor.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0361,  0.0298, -0.0393, -0.0253,  0.0455, -0.0426, -0.0075, -0.0253,\n",
       "          0.0179, -0.0178]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_tensor=torch.randn(size=(1,28,28))\n",
    "model_2(dummy_tensor.unsqueeze(dim=0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup loss function eval metrics and optimizer\n",
    "from helper_functions import accuracy_fn\n",
    "\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_2.parameters(),\n",
    "                            lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "-------------\n",
      "Train loss: 0.60444 | Train acc: 78.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:15<00:30, 15.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.3409, Test acc 87.8000\n",
      "Epoch: 2\n",
      "-------------\n",
      "Train loss: 0.32691 | Train acc: 88.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:30<00:15, 15.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.3159, Test acc 88.6833\n",
      "Epoch: 3\n",
      "-------------\n",
      "Train loss: 0.28579 | Train acc: 89.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:45<00:00, 15.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.2624, Test acc 90.7633\n",
      "\n",
      "Train time on cuda: 45.030 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "from helper_functions import print_train_time \n",
    "\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "train_time_start_model_2=timer()\n",
    "\n",
    "epochs=3\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch+1}\\n-------------\")\n",
    "    train_step(model=model_2,\n",
    "               data_loader=train_dataloader,\n",
    "               loss_fn=loss_fn,\n",
    "               optimizer=optimizer,\n",
    "               accuracy_fn=accuracy_fn,\n",
    "               device=device)\n",
    "    test_step(model=model_2,\n",
    "              data_loader=train_dataloader,\n",
    "              loss_fn=loss_fn,\n",
    "              accuracy_fn=accuracy_fn,\n",
    "              device=device)\n",
    "    \n",
    "train_time_end_model_2=timer()\n",
    "total_train_time_model_2=print_train_time(start=train_time_start_model_2,\n",
    "                                          end=train_time_end_model_2,\n",
    "                                          device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:01<00:00, 246.25it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV2',\n",
       " 'model_loss': 0.2914447784423828,\n",
       " 'model_acc': 89.44688498402556}"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_results=eval_model(model=model_2,\n",
    "                           data_loader=test_dataloader,\n",
    "                           loss_fn=loss_fn,\n",
    "                           accuracy_fn=accuracy_fn)\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_loss</th>\n",
       "      <th>model_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FashionMNISTModelV0</td>\n",
       "      <td>0.476639</td>\n",
       "      <td>83.426518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FashionMNISTModelV1</td>\n",
       "      <td>0.685001</td>\n",
       "      <td>75.019968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FashionMNISTModelV2</td>\n",
       "      <td>0.291445</td>\n",
       "      <td>89.446885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name  model_loss  model_acc\n",
       "0  FashionMNISTModelV0    0.476639  83.426518\n",
       "1  FashionMNISTModelV1    0.685001  75.019968\n",
       "2  FashionMNISTModelV2    0.291445  89.446885"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "#Previous models results\n",
    "model_1_results={'model_name': 'FashionMNISTModelV1',\n",
    " 'model_loss': 0.6850008368492126,\n",
    " 'model_acc': 75.01996805111821}\n",
    "\n",
    "model_0_results={'model_name': 'FashionMNISTModelV0',\n",
    " 'model_loss': 0.4766390025615692,\n",
    " 'model_acc': 83.42651757188499}\n",
    "\n",
    "compare_results=pd.DataFrame([model_0_results,\n",
    "                              model_1_results,\n",
    "                              model_2_results])\n",
    "compare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_loss</th>\n",
       "      <th>model_acc</th>\n",
       "      <th>training time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FashionMNISTModelV0</td>\n",
       "      <td>0.476639</td>\n",
       "      <td>83.426518</td>\n",
       "      <td>22.325502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FashionMNISTModelV1</td>\n",
       "      <td>0.685001</td>\n",
       "      <td>75.019968</td>\n",
       "      <td>25.005442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FashionMNISTModelV2</td>\n",
       "      <td>0.291445</td>\n",
       "      <td>89.446885</td>\n",
       "      <td>45.029907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name  model_loss  model_acc  training time\n",
       "0  FashionMNISTModelV0    0.476639  83.426518      22.325502\n",
       "1  FashionMNISTModelV1    0.685001  75.019968      25.005442\n",
       "2  FashionMNISTModelV2    0.291445  89.446885      45.029907"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Previous models\n",
    "total_train_time_model_0=22.325502400000005\n",
    "total_train_time_model_1=25.00544179999997\n",
    "\n",
    "compare_results[\"training time\"]=[total_train_time_model_0,\n",
    "                                  total_train_time_model_1,\n",
    "                                  total_train_time_model_2]\n",
    "compare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'model')"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_results.set_index(\"model_name\")[\"model_acc\"].plot(kind=\"bar\")\n",
    "plt.ylabel(\"accuracy(%)\")\n",
    "plt.xlabel(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
