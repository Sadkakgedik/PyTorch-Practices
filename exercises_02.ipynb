{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "# Import torch\n",
    "import torch\n",
    "\n",
    "# Exercises require PyTorch > 1.10.0\n",
    "print(torch.__version__)\n",
    "\n",
    "# TODO: Setup device agnostic code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug 21 13:39:31 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 536.99                 Driver Version: 536.99       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070 Ti   WDDM  | 00000000:06:00.0  On |                  N/A |\n",
      "|  0%   49C    P8              21W / 290W |   1213MiB /  8192MiB |     25%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2868    C+G   ....0_x64__8wekyb3d8bbwe\\HxOutlook.exe    N/A      |\n",
      "|    0   N/A  N/A      4132    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A      6864    C+G   ...GeForce Experience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A      8744    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A      9264    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      9660    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A     13396    C+G   ...paper_engine\\bin\\webwallpaper32.exe    N/A      |\n",
      "|    0   N/A  N/A     13936    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     15404    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe    N/A      |\n",
      "|    0   N/A  N/A     15556    C+G   ..._8wekyb3d8bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A     16600    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     16784    C+G   ...Programs\\Microsoft VS Code\\Code.exe    N/A      |\n",
      "|    0   N/A  N/A     17160    C+G   ...9.0_x64__cv1g1gvanyjgm\\WhatsApp.exe    N/A      |\n",
      "|    0   N/A  N/A     17828    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     19320    C+G   ...al\\Discord\\app-1.0.9016\\Discord.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What are 3 areas in industry where computer vision is currently being used?\n",
    "\n",
    "1- Autonomous Vehicles\n",
    "\n",
    "2- Healthcare\n",
    "\n",
    "3- Retail and E-commerce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Search \"what is overfitting in machine learning\" and write down a sentence about what you find\n",
    "\n",
    "It is to analyze a data too exactly that it may prevent future predictions and therefore unnecessary (that is the first thing that i understood from a 5 minute google search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Load the torchvision.datasets.MNIST() train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "0.15.0\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=datasets.FashionMNIST(root=\"data\",\n",
    "                                 train=True,\n",
    "                                 download=True,\n",
    "                                 transform=ToTensor(),\n",
    "                                 target_transform=None)\n",
    "\n",
    "test_data=datasets.FashionMNIST(root=\"data\",\n",
    "                                train=False,\n",
    "                                download=True,\n",
    "                                transform=ToTensor(),\n",
    "                                target_transform=None)\n",
    "\n",
    "len(train_data),len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import train_step,test_step,eval_model,accuracy_fn,set_seeds,print_train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "image,label=train_data[0]\n",
    "class_names=train_data.classes\n",
    "class_to_idx=train_data.class_to_idx\n",
    "\n",
    "BATCH_SIZE=32\n",
    "train_dataloader=DataLoader(dataset=train_data,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=True)\n",
    "test_dataloader=DataLoader(dataset=test_data,\n",
    "                           batch_size=BATCH_SIZE,\n",
    "                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "class ExerciseModelV1(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_shape:int,\n",
    "                 hidden_units:int,\n",
    "                 output_shape:int,):\n",
    "        super().__init__()\n",
    "        self.conv_block_1=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2))\n",
    "        )\n",
    "        self.conv_block_2=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2))\n",
    "        )\n",
    "        #Final layer (classifier layer)\n",
    "        self.classifier_layer=nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*49,#to be completed \n",
    "                      out_features=output_shape)\n",
    "\n",
    "        )\n",
    "    def forward(self,x:torch.tensor):\n",
    "        x=self.conv_block_1(x)\n",
    "        x=self.conv_block_2(x)\n",
    "        x=self.classifier_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: torch.Size([1, 28, 28])\n",
      "Label: 2, label size: torch.Size([])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGZCAYAAABmNy2oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAWOElEQVR4nO3dXWyfdfk/8Ktb242yzo5tDlaHDLdsPAhsYUkRY4YgBLKASgKRB8MwatiRBxjFIxNINHjowcTEbD5hRFEwJEtEBjP4EFhQEGQ8BMbINgYbK3vo1tmW34Hxigj//Hd9pKXM1yvZwba+e9/f+/tt37239b2ON998880AgIiY8l6fAACTh1IAICkFAJJSACApBQCSUgAgKQUAklIAICkFAJJSYNJYv359dHR05I/Ozs740Ic+FKtXr47t27eX319HR0d885vfzJ8/9NBD0dHREQ899NC7d9JwjOl8r08A/tO6deti6dKlcejQofj9738f3/rWt2LTpk3xt7/9LY4//vj3+vTgmKYUmHTOPPPMOPfccyMi4oILLojR0dG49dZb45577olrr732PT678XPo0KGYPn16dHR0vNenwv8wf3zEpDcwMBARES+99FKsXLkyVq5c+ba3ueGGG+KUU05pev+/+c1v4rzzzouenp7o7e2NT33qU/GnP/0pf/+ee+6Jjo6OeOCBB96WXbt2bXR0dMQTTzyRv7Z58+a4/PLL44QTTojp06fHsmXL4q677npL7l9/VPbb3/42brzxxpg7d2709PTE8PBw02OAd4tSYNJ7/vnnIyJi7ty57/r7vvPOO+OKK66ImTNnxs9+9rP4wQ9+EHv37o2VK1fGww8/HBERq1atig9+8IOxbt26t+XXr18fy5cvj7POOisiIh588ME4//zzY3BwML73ve/FvffeG+ecc05cffXVsX79+rflb7zxxujq6oof//jH8ctf/jK6urre9ccIFf74iElndHQ0RkZG4vDhw7Fp06a47bbbore3Ny6//PL46U9/+q4dZ2xsLL761a/GRz/60diwYUNMmfLPr5Euu+yy+MhHPhJf+9rX4g9/+EN0dnbGddddF2vXro033ngjPvCBD0RExNNPPx2PPPJIfPe73833uWbNmjjjjDNi48aN0dn5zw+vSy65JHbv3h3f+MY34vOf/3weJyLiwgsvjDvuuONde0zw33KnwKQzMDAQXV1d0dvbG6tWrYoTTzwxNmzYEPPmzXtXj/PMM8/Ejh074vrrr3/LJ+oZM2bElVdeGX/+859jaGgoIv75Ff2hQ4fi5z//eb7dunXrYtq0aXHNNddExD/vaLZs2ZJ/7zEyMpI/Lrvssti5c2c888wzbzmHK6+88l19TPDfcqfApPOjH/0oTjvttOjs7Ix58+bFSSedNC7H2bNnT0TEO77/+fPnx9jYWOzduzd6enrijDPOiBUrVsS6deviS1/6UoyOjsZPfvKTuOKKK+KEE06IiIhdu3ZFRMTNN98cN9988zsec/fu3W/5+Xg9NmilFJh0TjvttPzXR/9p+vTp8cYbb7zt1//zk+3RmD17dkRE7Ny5822/t2PHjpgyZUrMmjUrf2316tWxZs2aePrpp+OFF16InTt3xurVq/P358yZExERt9xyS3z2s599x2MuWbLkLT/3L42YbPzxEe8rp5xySjz77LNv+Vc6e/bsiT/+8Y/l97VkyZLo7++PO++8M/79f6U9ePBg3H333fkvkv7lc5/7XEyfPj3Wr18f69evj/7+/rj44ovf8v4WL14cjz/+eJx77rnv+KO3t7fxkcPEcKfA+8r1118fd9xxR1x33XXxxS9+Mfbs2RO33357zJw5s/y+pkyZErfffntce+21sWrVqvjyl78cw8PD8Z3vfCcGBwfj29/+9lvevq+vLz7zmc/E+vXrY3BwMG6++ea3/F1ERMQdd9wRl156aVxyySVxww03RH9/f7z++uvx9NNPx2OPPRa/+MUv/qvHD+PNnQLvK+eff3788Ic/jKeeeiquuOKKuO222+KWW255x+9dOBrXXHNN3HPPPbFnz564+uqrY/Xq1TFz5sx48MEH4+Mf//jb3n716tXx6quvxpEjR+KGG2542+9fcMEF8cgjj0RfX1985StfiYsuuihuuumm+N3vfhcXXXRR0znCROp489/vmwH4n+ZOAYCkFABISgGApBQASEoBgKQUAEhH/c1rLd+OP3Xq1HKm1ejo6IQdayL8v2Ye/n8WL15czrRcu09+8pPlzN69e8uZiIgNGzaUMzt27Gg6VtW/f8fz0VqxYkXTsf41z12xZcuWpmNVPfroo+XM5s2bx+FM3j0tn78m++eho/kOBHcKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJKUAQDrq/6O5ZRDvWHTOOeeUM5dcckk5s3v37nImImJoaKicOXz4cDkzNjZWzlx66aXlTETEwMBAOdNy/WbNmlXOdHd3lzP79+8vZyIinnrqqXLmzjvvLGfmzp1bzrSM/LW+xrdt21bO3HfffeVM6/M0mRnEA6BEKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJD+pwfxLrjggnJm5cqV5cwDDzxQzsyePbuciWgbqmsZ0RseHi5nduzYUc5EREydOrWcaRm3O+6448qZltG01iG4FmeeeWY5s2/fvnJmdHS0nOnp6SlnItoGEp988sly5te//nU5M9kZxAOgRCkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIAqfO9PoH30tKlS8uZv/71r+VMyxpkV1dXORPRtnDZskLa8pgWLVpUzkS0rbi2PKYW06ZNK2cWL17cdKyWx9SSaVnoPXToUDnTcu0iIjZt2lTOnHfeeU3H+l/kTgGApBQASEoBgKQUAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABIx8wgXnd3dznT19dXzrSMeG3ZsqWcaRm2azU8PDwhxxkdHZ2wXMsQXOv5VY2MjExYruUxzZkzp5xp0Tr6OGvWrHKmZcBxwYIF5czLL79czkw27hQASEoBgKQUAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABISgGAdMwM4i1fvryc2bp1azkzMDBQzrz44ovlzPbt28uZiLYRr4kaxGsZqWvVMgQ3UcN7nZ1tH3YTdazDhw+XM2NjY+VM6+tuypT617JDQ0PlTMvnFIN4ABxTlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgDpmBnEW7ZsWTnzyiuvlDP3339/OfOFL3yhnPn6179ezkS0DZO1OP7448uZkZGRpmO1DNW1aD2/qmnTpjXlurq6ypkDBw40Havq4MGD5cynP/3ppmO1vB42btxYzqxYsaKcuffee8uZycadAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCOmUG8k08+uZzZsWNHOfPoo4+WM2vWrClnLr744nImom34a/bs2eVMy3hc67DdRB2rJTN16tRyZqKG9yLaxve2bdtWzrSMx7UO4l199dXlTG9vbznT19dXzhwL3CkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkI6ZldSW5cmWBcmTTjqpnNm0aVM5c9VVV5UzEREbNmxoylUNDg6WMxO5DtriyJEj5UzLsuqePXvKmYiI4eHhcmb+/PnlTMtK6rp168qZxx9/vJyJiHjuuefKmeXLl5czLa/xltXciPYF4fHgTgGApBQASEoBgKQUAEhKAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABIx8wgXn9/fzmzefPmcmb69OnlzH333VfOLFmypJyJiBgYGChnnnzyyaZjVY2NjU3IcSIiuru7JyQzUSN6EREzZswoZ1rG95YtW1bODA0NlTMtQ5ERbeN2LUN1fX195cyCBQvKmYiIrVu3NuXGgzsFAJJSACApBQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgKQUAklIAIE26QbyW4aqIiM7O+kNpGfHq7e2dkOOsXr26nImIePTRR8uZ448/vpxpeZ4GBwfLmYiIKVPqX7tMmzat6VhVLa+74447rulYLc/T7t27y5kPf/jD5cwpp5xSzuzatauciWgbBnz55ZfLmZbnds6cOeVMhEE8ACYppQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAECadIN4CxcubMpt3769nGkZdWsZGFuzZs2EHCcioqenp5yZNWtWObNv375ypuXcIiK6u7ubclWjo6PlTMu4XctxIiIOHjxYzpx00knlTMtr7y9/+Us5c/bZZ5czEREPP/xwOXPo0KFyZtu2beVMf39/ORMRsXnz5qbceHCnAEBSCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAECadCup8+bNa8qNjIyUMy1rlaeeemo589prr5Uz119/fTkTEXHhhReWM0899VQ503LtWlZpJ9JEnd+RI0eacn19feXMq6++Ws4MDAyUM3fddVc5Mzg4WM5ERCxatKic2bVrVznT8jnl3HPPLWciIu69996m3HhwpwBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAEBSCgCkSTeIN2fOnKbcgQMHyplp06aVMwsXLixn1q5dW8709vaWM6254eHhcqa7u7ucaRnRa9UybtcyVNdynJahtYiImTNnljMtz21/f3858/3vf7+cOeuss8qZiIilS5eWM/fff38588ILL5QzH/vYx8qZycadAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCOmUG8Xbt2lTMHDx4sZ/r6+sqZHTt2lDOLFi0qZyLaBtBahuBahveGhobKmYi2Ib2WscOW6zCRWp7blmu3ffv2cmb+/PkTcpyItiG9T3ziE+XMiy++WM4cC9wpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAGnSDeK1DK1FRLz00kvlzJ49e8qZ8847r5xpMW/evKZcyxBcy2haZ2f9pdPT01POREQMDg425SbCRF27iLZBvJbXw/79+8uZq666qpy59dZby5mItut36qmnljPPP/98ObNv375yJiKiu7u7nBmvAUd3CgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAECadIN4LQNeERFjY2PlTF9fXzmzffv2cqbF4sWLm3KvvfZaOXP48OFypnXcrsXu3bvLmalTp47DmbxdyyhZ67m1fGwMDQ2VM9u2bStnzj777HKm1WOPPVbOtLyGWoYBW653RNsQaMug59FwpwBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAmnQrqXPmzGnK7d27t5yZNWtWObNr165ypsXChQubci2rnZ2d9ZdBy9Ln6OhoORMRMTIyUs60PKbu7u5y5tChQxNynIi26zdjxoxy5sCBA+VMy3PUqmUJuGURuUV/f39TbsGCBeWMlVQAxp1SACApBQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgKQUAklIAII3rIF7L8FfrENzQ0FA50zJetX///nKmxZIlS5pyGzduLGd6e3vLmZZBvInU1dVVzrSM6E3UWF9E2zVvuQ49PT3lzL59+8qZc845p5yJiNi6dWs5c9ZZZ5UzLc9t6+jj3Llzm3LjwZ0CAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkMZ1EG/atGnlzPDw8DicyTvr6+srZ1qG91qceOKJTbnXXnutnGl5nlqGvw4fPlzORESMjY1NSKbFkSNHypnW1/iMGTOaclVTptS/VhwcHCxnWkfgtm3bVs6sWLGi6VhV27dvb8pNpoFJdwoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAGtdBvHnz5pUz+/fvbzpWZ2f9obRktmzZUs60XIfW4b2dO3eWMy3n19vbW8688sor5UxExOzZs8uZlsG+OXPmlDMtz1PLiF6rltHHXbt2lTMzZ84sZ3p6esqZiIh9+/aVMy0jhC1DkS2ZiIiFCxc25caDOwUAklIAICkFAJJSACApBQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgjesgXss4VMuQWUTE1KlTy5mWsbCNGzeWM6effno589xzz5UzEW3XocWsWbPKmdYhuJZjdXV1lTMtr73+/v5ypmXQLSJibGysKVfVMlT34osvljMnn3xyORPR9rHRcs1bXnctw3sR7UN648GdAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBpXFdSFyxYUM68/vrrTcfav39/OTM4OFjOtKxvDgwMlDPPP/98OTOR9u7dW860PEcREXPmzCln/vGPf5Qze/bsKWdalz5btCxwtl7zqpbl0uXLlzcda9myZeXM9OnTm45VtWPHjqZcy+fK8eJOAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABISgGApBQASEoBgKQUAEjjOoi3YsWK8Xz3b7F06dJypmVobeXKleVMT09POdMyztZq3rx55UzL0Fp3d3c5ExExf/78cqZlmGx0dHRCMq1aXq/Tpk0rZ1qep1deeaWcGRkZKWciIk499dSmXFVfX1850zpsd8IJJzTlxoM7BQCSUgAgKQUAklIAICkFAJJSACApBQCSUgAgKQUAklIAICkFAJJSACCN6yDe+vXry5mFCxc2Hatl+Ovuu+8uZ5YvX17OtAzODQ4OljOthoaGypmpU6eWMyeeeGI502rKlPrXOwcPHixnDh8+XM7MmjWrnIloGyFsGdHbvXt3OdPy8df6Gm957f3qV78qZ4aHh8uZlueo9VjjxZ0CAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkMZ1EO/ll1+ekMxE6u3tLWcGBgbKmZaRuoi2sbAjR46UM93d3eVMy7lFtA2nTZ8+vZxpGaprObczzzyznImIePzxx8uZ+fPnlzMtr4eWa7d9+/ZyJqJtdO6+++5rOtb/IncKACSlAEBSCgAkpQBAUgoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKAKRxXUk9Fq1ataqcaV0HbTF79uxyZsGCBeVMy5JmT09POTPZtSx2Ll26dBzO5J0tWrSonHniiSfKmb6+vnLm8OHD5UxE2/W76aabypm1a9eWM60f66Ojo0258eBOAYCkFABISgGApBQASEoBgKQUAEhKAYCkFABISgGApBQASEoBgKQUAEgdb7755ptH9YYdHeN9Lu8LLQNjy5cvL2eeffbZciYiYuvWreVMy2MaGRkpZ1odOHCgnGkZ39u9e3c502LhwoVNueHh4XKmZezw73//ezkzkU4//fRyZnBwsJx58MEHy5lWLUN6LSN6R/Pp3p0CAEkpAJCUAgBJKQCQlAIASSkAkJQCAEkpAJCUAgBJKQCQlAIASSkAkDqP9g2PcjcPgPcxdwoAJKUAQFIKACSlAEBSCgAkpQBAUgoAJKUAQFIKAKT/A0FyME5yhGpNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_features_batch,train_labels_batch=next(iter(train_dataloader))\n",
    "\n",
    "random_idx=torch.randint(0,len(train_features_batch),size=[1]).item()\n",
    "\n",
    "img=train_features_batch[random_idx]\n",
    "label=train_labels_batch[random_idx]\n",
    "\n",
    "plt.imshow(img.squeeze(),cmap=\"gray\")\n",
    "plt.axis(False)\n",
    "plt.title(class_names[label])\n",
    "print(f\"Image size: {img.shape}\")\n",
    "print(f\"Label: {label}, label size: {label.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model_1=ExerciseModelV1(input_shape=1,\n",
    "                        hidden_units=10,\n",
    "                        output_shape=len(class_names)).to(device)\n",
    "\n",
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.SGD(params=model_1.parameters(),\n",
    "                          lr=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "------------\n",
      "Train loss: 0.59519 | Train acc: 78.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:16<01:04, 16.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.3899, Test acc 86.3319\n",
      "Epoch: 2\n",
      "------------\n",
      "Train loss: 0.36261 | Train acc: 87.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:25<00:36, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.3593, Test acc 86.5715\n",
      "Epoch: 3\n",
      "------------\n",
      "Train loss: 0.32727 | Train acc: 88.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:35<00:22, 11.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.3182, Test acc 88.5383\n",
      "Epoch: 4\n",
      "------------\n",
      "Train loss: 0.30726 | Train acc: 88.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:45<00:10, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.3324, Test acc 87.7696\n",
      "Epoch: 5\n",
      "------------\n",
      "Train loss: 0.29344 | Train acc: 89.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:54<00:00, 10.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test loss: 0.3202, Test acc 88.6681\n",
      "\n",
      "Train time on cuda: 54.229 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "set_seeds()\n",
    "\n",
    "from timeit import default_timer as timer \n",
    "\n",
    "train_start_time_model_1=timer()\n",
    "\n",
    "epochs=5\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch+1}\\n------------\")\n",
    "    train_step(model=model_1,\n",
    "               data_loader=train_dataloader,\n",
    "               loss_fn=loss_fn,\n",
    "               optimizer=optimizer,\n",
    "               accuracy_fn=accuracy_fn,\n",
    "               device=device)\n",
    "    test_step(model=model_1,\n",
    "              data_loader=test_dataloader,\n",
    "              loss_fn=loss_fn,\n",
    "              accuracy_fn=accuracy_fn,\n",
    "              device=device)\n",
    "\n",
    "train_end_time_model_1=timer()\n",
    "\n",
    "total_train_time_model_1=print_train_time(start=train_start_time_model_1,\n",
    "                                          end=train_end_time_model_1,\n",
    "                                          device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 316.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'ExerciseModelV1',\n",
       " 'model_loss': 0.32021450996398926,\n",
       " 'model_acc': 88.66813099041534}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helper_functions import eval_model\n",
    "model_1_results=eval_model(model=model_1,\n",
    "                           data_loader=test_dataloader,\n",
    "                           loss_fn=loss_fn,\n",
    "                           accuracy_fn=accuracy_fn)\n",
    "model_1_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
